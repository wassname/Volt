{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce655bc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T07:26:15.161022Z",
     "start_time": "2022-07-16T07:26:15.142775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning no robinhood utils.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import pandas as pd\n",
    "import gpytorch\n",
    "import matplotlib.style as style\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "palette = [\"red\", \"blue\", \"green\", \"orange\", \"purple\", \"#AF7595\", \"#E6480F\", \"#FA9500\"]\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (14.0, 6)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "from loguru import logger\n",
    "logger.remove()\n",
    "logger.add(os.sys.stdout, colorize=True, format=\"<level>{time} | {message}</level>\")\n",
    "\n",
    "from voltron.likelihoods import VolatilityGaussianLikelihood\n",
    "from voltron.models import SingleTaskVariationalGP\n",
    "from voltron.kernels import BMKernel, VolatilityKernel\n",
    "from voltron.train_utils import TrainVolModel, TrainVoltMagpieModel, LearnGPCV, TrainDataModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fb0fb7-c533-4474-8b74-ef4f7c38da76",
   "metadata": {},
   "source": [
    "## Generate Some Synthetic SDE Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b74d19b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T07:23:41.627613Z",
     "start_time": "2022-07-16T07:23:41.610314Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(2019)\n",
    "torch.random.manual_seed(2019)\n",
    "\n",
    "# F0 = 10 ## init price\n",
    "# V0 = 0.2 ## init price\n",
    "# mu = 0.05 ## rate of return\n",
    "\n",
    "# alpha = 1.25\n",
    "# beta = 0.9\n",
    "# rho = -0.2\n",
    "\n",
    "T = 1 ## Time of Simulation\n",
    "steps = 800 ## steps per time\n",
    "dt = T/(steps) ## delta t\n",
    "\n",
    "# dW = np.random.normal(0, np.sqrt(dt), steps*T)\n",
    "# dZ = rho * dW + np.sqrt(1 - rho **2) * np.random.normal(0, np.sqrt(dt), steps*T)\n",
    "\n",
    "\n",
    "# train_x = time = torch.linspace(0, T, steps-1) + dt\n",
    "test_x = torch.linspace(T + dt, 1.5*T, int(.5*steps)-1) + dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0389e233",
   "metadata": {},
   "source": [
    "# Replace with real data\n",
    "\n",
    "It should be \n",
    "- steps = 400\n",
    "- full_x: a float tensor, of steps from 0 to 1\n",
    "- full_y: the log returns\n",
    "\n",
    "and note that\n",
    "- F was price\n",
    "- V was vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ede9e3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import requests_cache\n",
    "# let's cache where we can\n",
    "session = requests_cache.CachedSession('../data/interim/.yfinance.cache')\n",
    "session.headers['User-agent'] = 'Mozilla/5.0 (Windows NT 10.0; rv:91.0) Gecko/20100101 Firefox/91.0'\n",
    "\n",
    "ticker=\"MS\"\n",
    "data = yf.download(tickers=ticker, session=session, period='2y', interval=\"1h\", progress=False)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8f23bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(steps, len(data)-steps, len(data))\n",
    "split_i = np.random.randint(steps, len(data)-steps)\n",
    "print('split_i', split_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4b7790",
   "metadata": {},
   "outputs": [],
   "source": [
    "ahead = test_x.shape[0]\n",
    "F_all = data['Adj Close']\n",
    "# F_all = d#.iloc[split_i-steps:split_i+steps]\n",
    "# data_train = data_all.head(steps)\n",
    "# data_test = data_all.tail(steps)\n",
    "\n",
    "# F_s = data_train.tail(steps)['Close']\n",
    "# F = F_s.values\n",
    "# F_s_test = data_test['Close']\n",
    "\n",
    "# log_returns_all = np.log(d.pct_change().iloc[split_i-steps:split_i+steps].iloc[1:]+1)\n",
    "log_returns_all = np.log(F_all.pct_change()+1)\n",
    "V_all = pd.Series(log_returns_all).rolling(6).std()\n",
    "\n",
    "# restrict to our section\n",
    "F_all = F_all.iloc[split_i-steps:split_i+steps].values\n",
    "log_returns_all = log_returns_all.iloc[split_i-steps:split_i+steps].iloc[1:].values\n",
    "V_all = V_all.iloc[split_i-steps:split_i+steps].iloc[1:].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e44371",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=100)\n",
    "ax.plot(F_all, label='Price')\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(V_all, color = palette[1], label='Vol')\n",
    "\n",
    "ax.set_ylabel(\"Price\")\n",
    "ax2.set_ylabel(\"Vol\")\n",
    "\n",
    "fig.legend(bbox_to_anchor=(0.9, 0.9))\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc27ac2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_x = torch.FloatTensor(np.linspace(0, T, steps-1)) + dt\n",
    "# full_y = torch.FloatTensor(log_returns_all)\n",
    "# full_x.shape, full_y.shape, T, steps, dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee913293-538f-406d-b1c9-ee33ee4976f0",
   "metadata": {},
   "source": [
    "## Learning A Volatility Model\n",
    "\n",
    "While we show the volatility in the plot above, we do not typically get to observe this path directly. Therefore the first step in the Volt modeling pipeline is to learn a model of the historic volatility. For this we rely on [GCPV](https://arxiv.org/abs/1006.1350).\n",
    "\n",
    "First specify the train and test domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468e0fa2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T07:24:56.512073Z",
     "start_time": "2022-07-16T07:24:56.498295Z"
    }
   },
   "outputs": [],
   "source": [
    "full_x = torch.FloatTensor(np.linspace(0, T, steps-1)) + dt\n",
    "full_y = torch.FloatTensor(log_returns_all[1:steps])\n",
    "\n",
    "train_x = full_x\n",
    "train_y = full_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59518eac-2240-4a8d-9ac7-c6ec42ef7a6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T07:24:59.218824Z",
     "start_time": "2022-07-16T07:24:56.645680Z"
    }
   },
   "outputs": [],
   "source": [
    "likelihood = VolatilityGaussianLikelihood(K=20, param=\"exp\")\n",
    "# likelihood.raw_a.data -= 4.\n",
    "from gpytorch.constraints import Interval\n",
    "covar_module = BMKernel(vol=0.99, vol_constraint=Interval(0., 10.))\n",
    "# covar_module = VolatilityKernel()\n",
    "model = SingleTaskVariationalGP(\n",
    "    init_points=train_x.view(-1,1), likelihood=likelihood, use_piv_chol_init=False,\n",
    "    mean_module = gpytorch.means.ConstantMean(), covar_module=covar_module, \n",
    "    learn_inducing_locations=False, use_whitened_var_strat=False\n",
    ")\n",
    "model.initialize_variational_parameters(likelihood, train_x, y=train_y)\n",
    "\n",
    "training_iterations = 500\n",
    "\n",
    "model.train()\n",
    "likelihood.train()\n",
    "optimizer = torch.optim.Adam([\n",
    "    {\"params\": model.parameters()}, \n",
    "    # {\"params\": likelihood.parameters(), \"lr\": 0.1}\n",
    "], lr=0.01)\n",
    "mll = gpytorch.mlls.VariationalELBO(likelihood, model, train_y.numel(), combine_terms = True)\n",
    "\n",
    "print_every = 50\n",
    "for i in range(training_iterations):\n",
    "    # Zero backpropped gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Get predictive output\n",
    "    with gpytorch.settings.num_gauss_hermite_locs(75):\n",
    "        output = model(train_x)\n",
    "        # Calc loss and backprop gradients\n",
    "        loss = -mll(output, train_y)\n",
    "        loss.backward()\n",
    "        if i % print_every == 0:\n",
    "            print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iterations, loss.item()))\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e15ba9e-4d2f-4d64-9e22-65c2944d1683",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T07:24:59.234686Z",
     "start_time": "2022-07-16T07:24:59.220369Z"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "likelihood.eval()\n",
    "predictive = model(full_x)\n",
    "pred_scale = likelihood(predictive, return_gaussian=False).scale.mean(0).detach()\n",
    "pred_scale = likelihood(predictive, return_gaussian=False).scale.max(0)[0].detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5ebe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# likelihood(predictive, return_gaussian=False).scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bd22fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# likelihood(predictive, return_gaussian=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7010daad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"we really need to capture the max spikes or we wont have a good model\")\n",
    "plt.plot(V_all)\n",
    "plt.plot(pred_scale)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de0e5b9",
   "metadata": {},
   "source": [
    "## Now Train the Volt Model\n",
    "\n",
    "Given the GCPV volatility path we can now train a GP over the historic volatility, and then learn the final Volt model to forecast with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef13c254-6ab1-4133-b9a5-f29d45aedd20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T07:25:00.938913Z",
     "start_time": "2022-07-16T07:24:59.235659Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vmod, vlh = TrainVolModel(train_x, pred_scale, kernel=\"bm\", train_iters=500, printing=True)\n",
    "# vmod, vlh = TrainVolModel(train_x, pred_scale, kernel=\"fbm\", vol=0.99, vol_constraint=Interval(0., 10.), train_iters=500, printing=True)\n",
    "# vmod, vlh = TrainVolModel(train_x, pred_scale, kernel=\"bm\", vol=0.99, vol_constraint=Interval(0., 10.), train_iters=500, printing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f9b902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(pred_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18feab33-3f3d-4bc7-9417-54bef6e221ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T07:25:04.098416Z",
     "start_time": "2022-07-16T07:25:00.940596Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "F = F_all[:steps]\n",
    "V = V_all[:steps]\n",
    "dmod, dlh = TrainDataModel(train_x, torch.FloatTensor(F)[1:], vmod, vlh, pred_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91af0297-6307-45dc-be37-a703b07c3b16",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ff54fb-b125-4ab0-add1-8cb13bf0c744",
   "metadata": {},
   "source": [
    "We now have a trained data model which is the main Volt class. To forecast we specify how many volatility paths we want to draw, `nvol`, and how many price paths we want to draw for each volatility path, `npx`. Then we simply loop through and draw the corresponding samples using the `GeneratePrediction` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14743ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T07:25:04.157531Z",
     "start_time": "2022-07-16T07:25:04.099715Z"
    }
   },
   "outputs": [],
   "source": [
    "dmod.eval();\n",
    "dlh.eval();\n",
    "dmod.vol_model.eval();\n",
    "\n",
    "nvol = 60\n",
    "npx = 1\n",
    "px_paths = torch.zeros(npx*nvol, test_x.shape[0])\n",
    "vol_paths = torch.zeros(nvol, test_x.shape[0])\n",
    "\n",
    "for vidx in range(nvol):\n",
    "#     print(vidx)\n",
    "    vol_pred = dmod.vol_model(test_x).sample().exp()\n",
    "    vol_paths[vidx, :] = vol_pred.detach()\n",
    "    \n",
    "    # FIXME hack, I don't know why I need the x10 here\n",
    "    px_pred = dmod.GeneratePrediction(test_x, vol_pred*10, npx).exp()\n",
    "    px_paths[vidx*npx:(vidx*npx + npx), :] = px_pred.detach().T\n",
    "\n",
    "px_paths.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9a0f25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T08:31:56.274593Z",
     "start_time": "2022-07-16T08:31:56.252823Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae84ab49-1e70-4922-a035-c607a5bbf551",
   "metadata": {},
   "source": [
    "## Put It All Together\n",
    "\n",
    "Below we plot the full hierarchy - the learned volatility path, the predicted volatility paths into the future, and the predicted paths conditioned on the predicted volatility paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ac3139",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T07:25:04.421290Z",
     "start_time": "2022-07-16T07:25:04.158746Z"
    }
   },
   "outputs": [],
   "source": [
    "def FormatAx(ax):\n",
    "    ax.set_xlim(0, test_x.max())\n",
    "#     ax.axvline(train_time.max(), ls=\"--\", c='k', lw=0.5)\n",
    "\n",
    "fig, ax = plt.subplots(3, 1, figsize = (8, 10), dpi=100, facecolor = \"w\")\n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "\n",
    "## vol & log return plot ##\n",
    "ax[0].plot(train_x, F[1:], label='Data', alpha=0.8)\n",
    "ax2 = ax[0].twinx()\n",
    "ax2.plot(train_x, V[1:], color = palette[1], label='Volatility')\n",
    "ax[0].set_ylabel(\"Y\")\n",
    "ax2.set_ylabel(\"Vol\")\n",
    "# ax[0].legend(bbox_to_anchor=(0.9, 0.9))\n",
    "\n",
    "custom_lines = [Line2D([0], [0], color=palette[0], lw=2., alpha=0.8,label=\"Data\"),\n",
    "                Line2D([0], [0], color=palette[1], lw=2., label=\"Volatility\")]\n",
    "\n",
    "ax[0].legend(handles=custom_lines,loc=\"upper right\", bbox_to_anchor=(1.07, 1.), \n",
    "             frameon=False, fontsize=18)\n",
    "\n",
    "\n",
    "## Vol and Forecast Plot ##\n",
    "ax[1].plot(train_x, V[1:], color = palette[1], alpha=0.75, label=\"True Vol.\")\n",
    "ax[1].plot(train_x, pred_scale, color = palette[-2], label = \"Learned Vol.\")\n",
    "ax[1].plot(test_x, vol_paths[0, :].T, color=palette[-1], alpha=0.5, label=\"Predicted Vol.\")\n",
    "ax[1].plot(test_x, vol_paths[1:, :].T, color=palette[-1], alpha=0.5)\n",
    "ax[1].set_ylabel(\"Vol\")\n",
    "ax[1].legend(loc=\"upper right\", bbox_to_anchor=(0.8, 1.1), frameon=False, fontsize=18)\n",
    "\n",
    "## Price and Forecast Plot ##\n",
    "ax[2].plot(train_x, F[1:], color=palette[0], alpha=0.8, label=\"Data\")\n",
    "ax[2].plot(test_x, px_paths[1:, :].T, color=palette[2], alpha=0.7)\n",
    "ax[2].plot(test_x, px_paths[0, :].T, color=palette[2], alpha=0.7, label=\"Predictions\")\n",
    "# s=px_paths.std(0)\n",
    "# m=px_paths.mean(0)\n",
    "# ax[2].fill_between(test_x, m-s, m+s, alpha=0.2, color=palette[2])\n",
    "\n",
    "F_s_test = F_all[steps:steps+steps//2-1]\n",
    "ax[2].plot(test_x, F_s_test, color=palette[1], alpha=0.7, label=\"True\")\n",
    "\n",
    "\n",
    "# ax[2].plot(F_all.values, color=palette[1], alpha=0.7, label=\"True\")\n",
    "\n",
    "ax[2].set_ylabel(\"Y\")\n",
    "ax[2].set_xlabel(\"X\")\n",
    "ax[2].legend(loc=\"upper right\", bbox_to_anchor=(0.5, 1.1), frameon=False, fontsize=18)\n",
    "## General Adjustments ##\n",
    "FormatAx(ax[0])\n",
    "FormatAx(ax[1])\n",
    "FormatAx(ax[2])\n",
    "\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64dc9d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f45436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FormatAx(ax):\n",
    "    ax.set_xlim(0, test_x.max())\n",
    "#     ax.axvline(train_time.max(), ls=\"--\", c='k', lw=0.5)\n",
    "\n",
    "fig, ax = plt.subplots(3, 1, figsize = (8, 10), dpi=100, facecolor = \"w\")\n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "\n",
    "## vol & log return plot ##\n",
    "ax[0].plot(train_x, F[1:], label='Data', alpha=0.8)\n",
    "ax2 = ax[0].twinx()\n",
    "ax2.plot(train_x, V[1:], color = palette[1], label='Volatility')\n",
    "ax[0].set_ylabel(\"Y\")\n",
    "ax2.set_ylabel(\"Vol\")\n",
    "# ax[0].legend(bbox_to_anchor=(0.9, 0.9))\n",
    "\n",
    "custom_lines = [Line2D([0], [0], color=palette[0], lw=2., alpha=0.8,label=\"Data\"),\n",
    "                Line2D([0], [0], color=palette[1], lw=2., label=\"Volatility\")]\n",
    "\n",
    "ax[0].legend(handles=custom_lines,loc=\"upper right\", bbox_to_anchor=(1.07, 1.), \n",
    "             frameon=False, fontsize=18)\n",
    "\n",
    "\n",
    "## Vol and Forecast Plot ##\n",
    "ax[1].plot(train_x, V[1:], color = palette[1], alpha=0.75, label=\"True Vol.\")\n",
    "ax[1].plot(train_x, pred_scale, color = palette[-2], label = \"Learned Vol.\")\n",
    "# ax[1].plot(test_x, vol_paths[0, :].T, color=palette[-1], alpha=0.5, label=\"Predicted Vol.\")\n",
    "# ax[1].plot(test_x, vol_paths[1:, :].T, color=palette[-1], alpha=0.5)\n",
    "s=vol_paths.std(0)\n",
    "m=vol_paths.mean(0)\n",
    "ax[1].fill_between(test_x, m-s, m+s, alpha=0.2, color=palette[1], label=\"Predicted Vol.\")\n",
    "\n",
    "\n",
    "V_s_test = V_all[steps:steps+steps//2-1]\n",
    "ax[1].plot(test_x, V_s_test, color=palette[3], alpha=0.7, label=\"True\")\n",
    "\n",
    "ax[1].set_ylabel(\"Vol\")\n",
    "ax[1].legend(loc=\"upper right\", bbox_to_anchor=(0.8, 1.1), frameon=False, fontsize=18)\n",
    "\n",
    "## Price and Forecast Plot ##\n",
    "ax[2].plot(train_x, F[1:], color=palette[0], alpha=0.8, label=\"Data\")\n",
    "# ax[2].plot(test_x, px_paths[1:, :].T, color=palette[2], alpha=0.7)\n",
    "# ax[2].plot(test_x, px_paths[0, :].T, color=palette[2], alpha=0.7, label=\"Predictions\")\n",
    "s=px_paths.std(0)\n",
    "m=px_paths.mean(0)\n",
    "ax[2].fill_between(test_x, m-s, m+s, alpha=0.2, color=palette[2], label=\"Predictions\")\n",
    "\n",
    "F_s_test = F_all[steps:steps+steps//2-1]\n",
    "ax[2].plot(test_x, F_s_test, color=palette[1], alpha=0.7, label=\"True\")\n",
    "\n",
    "\n",
    "# ax[2].plot(F_all.values, color=palette[1], alpha=0.7, label=\"True\")\n",
    "\n",
    "ax[2].set_ylabel(\"Y\")\n",
    "ax[2].set_xlabel(\"X\")\n",
    "ax[2].legend(loc=\"upper right\", bbox_to_anchor=(0.5, 1.1), frameon=False, fontsize=18)\n",
    "## General Adjustments ##\n",
    "FormatAx(ax[0])\n",
    "FormatAx(ax[1])\n",
    "FormatAx(ax[2])\n",
    "\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d418848-07d0-46c5-9c32-22c3eb38c847",
   "metadata": {},
   "source": [
    "## Note:\n",
    "\n",
    "There are some helpful utilities for training and forecasting that are used in the experimental code - we encourage you to play around with these utilities and try out Volt on new problems!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f658fc61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef48a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "volt",
   "language": "python",
   "name": "volt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
